{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4a72b0",
   "metadata": {},
   "source": [
    "# COMP8685 Deep Learning Assignment 3 (A3)\n",
    "\n",
    "Individual (25% of total mark)\n",
    "\n",
    "##  Task: \n",
    "You are required to develop a phyton code with additional comments to answer the question in the next section. \n",
    "\n",
    "##  Description: \n",
    "Create a code, in the provided template in Moodle, to train two Recurrent Neural Networks (RNNs) on the public benchmark dataset named Poker Hand available at: https://archive.ics.uci.edu/ml/datasets/Poker+Hand. \n",
    "\n",
    "Poker Hand dataset is composed of one training set named “poker-hand-training-true.data” and one testing set named “poker-hand-testing.data”. \n",
    "You will need to download both training and testing sets into your local disk by clicking the Data Folder link (see the image below).\n",
    "\n",
    "In Poker Hand dataset, each data sample (row) is an example of a hand consisting of five playing cards drawn from a standard deck of 52. Each card is described using two attributes (suit and rank), for a total of 10 predictive attributes. There is one Class attribute that describes the \"Poker Hand\". You can find more information about this dataset from: \n",
    "https://www.kaggle.com/datasets/rasvob/uci-poker-hand-dataset\n",
    "\n",
    "The dataset should be imported in the code. An example on how to import the dataset to your code can be found from the link below:\n",
    "https://www.kaggle.com/code/rasvob/uci-poker-dataset-classification\n",
    "\n",
    "Note: This is only a template. You can add more code/text cells if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bb2c61",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8448a03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 22:19:56.922913: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-24 22:19:56.922968: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM, CategoryEncoding\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e5b81a",
   "metadata": {},
   "source": [
    "## Import the training and testing set in the cell below (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfbb5617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (25010, 10)\n",
      "Shape of y_train: (25010,)\n",
      "Shape of X_test: (1000000, 10)\n",
      "Shape of y_test: (1000000,)\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# read the train data\n",
    "training = pd.read_csv('Data/poker-hand-training-true.data', sep=',', header=None)\n",
    "training.columns = ['S1', 'C1','S2', 'C2','S3', 'C3','S4', 'C4','S5', 'C5','Label']\n",
    "\n",
    "# read the test data\n",
    "testing = pd.read_csv('Data/poker-hand-testing.data', sep=',', header=None)\n",
    "testing.columns = ['S1', 'C1','S2', 'C2','S3', 'C3','S4', 'C4','S5', 'C5','Label']\n",
    "\n",
    "# seperate the train and test data from labels\n",
    "X_train, y_train = np.array(training.iloc[:,:-1]), np.array(training.iloc[:,-1])\n",
    "X_test, y_test = np.array(testing.iloc[:,:-1]), np.array(testing.iloc[:,-1])\n",
    "\n",
    "# print the shape of train and test data\n",
    "print(\"Shape of X_train: {}\".format(X_train.shape))\n",
    "print(\"Shape of y_train: {}\".format(y_train.shape))\n",
    "\n",
    "print(\"Shape of X_test: {}\".format(X_test.shape))\n",
    "print(\"Shape of y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a8b9d",
   "metadata": {},
   "source": [
    "## Implement the vanilla RNN in the cell below (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55b958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 10, 100)           10200     \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 10, 150)           37650     \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 10, 100)           25100     \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 50)                7550      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,010\n",
      "Trainable params: 81,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 22:20:00.783215: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-24 22:20:00.783248: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-24 22:20:00.783265: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter): /proc/driver/nvidia/version does not exist\n",
      "2023-03-24 22:20:00.783495: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# define model architecture\n",
    "\n",
    "model = Sequential() # create a sequential model\n",
    "\n",
    "model.add(SimpleRNN(units=100, input_shape=(10,1), activation='tanh', return_sequences=True))  # add recurrent neurons to the model\n",
    "model.add(SimpleRNN(units=150, activation='tanh', return_sequences=True))  # add recurrent neurons to the model\n",
    "model.add(SimpleRNN(units=100, activation='tanh', return_sequences=True)) \n",
    "model.add(SimpleRNN(units=50, activation='tanh'))\n",
    "\n",
    "model.add(Dense(units=10, activation='tanh')) # add dense layer as the output layer of the model\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3706ee",
   "metadata": {},
   "source": [
    "## Train the vanilla RNN based on the training set in the cell below (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cda5c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "196/196 - 5s - loss: 0.0644 - accuracy: 0.4976 - 5s/epoch - 27ms/step\n",
      "Epoch 2/30\n",
      "196/196 - 3s - loss: 0.0568 - accuracy: 0.5182 - 3s/epoch - 17ms/step\n",
      "Epoch 3/30\n",
      "196/196 - 3s - loss: 0.0563 - accuracy: 0.5281 - 3s/epoch - 17ms/step\n",
      "Epoch 4/30\n",
      "196/196 - 3s - loss: 0.0561 - accuracy: 0.5312 - 3s/epoch - 17ms/step\n",
      "Epoch 5/30\n",
      "196/196 - 3s - loss: 0.0559 - accuracy: 0.5347 - 3s/epoch - 17ms/step\n",
      "Epoch 6/30\n",
      "196/196 - 3s - loss: 0.0557 - accuracy: 0.5363 - 3s/epoch - 17ms/step\n",
      "Epoch 7/30\n",
      "196/196 - 3s - loss: 0.0557 - accuracy: 0.5361 - 3s/epoch - 17ms/step\n",
      "Epoch 8/30\n",
      "196/196 - 3s - loss: 0.0555 - accuracy: 0.5386 - 3s/epoch - 17ms/step\n",
      "Epoch 9/30\n",
      "196/196 - 3s - loss: 0.0554 - accuracy: 0.5413 - 3s/epoch - 18ms/step\n",
      "Epoch 10/30\n",
      "196/196 - 3s - loss: 0.0554 - accuracy: 0.5442 - 3s/epoch - 17ms/step\n",
      "Epoch 11/30\n",
      "196/196 - 3s - loss: 0.0548 - accuracy: 0.5520 - 3s/epoch - 17ms/step\n",
      "Epoch 12/30\n",
      "196/196 - 3s - loss: 0.0548 - accuracy: 0.5529 - 3s/epoch - 18ms/step\n",
      "Epoch 13/30\n",
      "196/196 - 3s - loss: 0.0544 - accuracy: 0.5624 - 3s/epoch - 17ms/step\n",
      "Epoch 14/30\n",
      "196/196 - 3s - loss: 0.0542 - accuracy: 0.5666 - 3s/epoch - 17ms/step\n",
      "Epoch 15/30\n",
      "196/196 - 3s - loss: 0.0537 - accuracy: 0.5721 - 3s/epoch - 17ms/step\n",
      "Epoch 16/30\n",
      "196/196 - 3s - loss: 0.0535 - accuracy: 0.5737 - 3s/epoch - 17ms/step\n",
      "Epoch 17/30\n",
      "196/196 - 3s - loss: 0.0535 - accuracy: 0.5758 - 3s/epoch - 17ms/step\n",
      "Epoch 18/30\n",
      "196/196 - 4s - loss: 0.0531 - accuracy: 0.5812 - 4s/epoch - 20ms/step\n",
      "Epoch 19/30\n",
      "196/196 - 4s - loss: 0.0525 - accuracy: 0.5910 - 4s/epoch - 21ms/step\n",
      "Epoch 20/30\n",
      "196/196 - 4s - loss: 0.0522 - accuracy: 0.5936 - 4s/epoch - 21ms/step\n",
      "Epoch 21/30\n",
      "196/196 - 4s - loss: 0.0512 - accuracy: 0.6051 - 4s/epoch - 22ms/step\n",
      "Epoch 22/30\n",
      "196/196 - 4s - loss: 0.0506 - accuracy: 0.6137 - 4s/epoch - 21ms/step\n",
      "Epoch 23/30\n",
      "196/196 - 4s - loss: 0.0497 - accuracy: 0.6227 - 4s/epoch - 21ms/step\n",
      "Epoch 24/30\n",
      "196/196 - 4s - loss: 0.0490 - accuracy: 0.6310 - 4s/epoch - 21ms/step\n",
      "Epoch 25/30\n",
      "196/196 - 4s - loss: 0.0480 - accuracy: 0.6407 - 4s/epoch - 20ms/step\n",
      "Epoch 26/30\n",
      "196/196 - 4s - loss: 0.0466 - accuracy: 0.6601 - 4s/epoch - 22ms/step\n",
      "Epoch 27/30\n",
      "196/196 - 4s - loss: 0.0454 - accuracy: 0.6734 - 4s/epoch - 21ms/step\n",
      "Epoch 28/30\n",
      "196/196 - 4s - loss: 0.0446 - accuracy: 0.6777 - 4s/epoch - 21ms/step\n",
      "Epoch 29/30\n",
      "196/196 - 4s - loss: 0.0440 - accuracy: 0.6851 - 4s/epoch - 22ms/step\n",
      "Epoch 30/30\n",
      "196/196 - 4s - loss: 0.0432 - accuracy: 0.6893 - 4s/epoch - 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f789c148af0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "encoder=CategoryEncoding(num_tokens=10, output_mode=\"one_hot\") # one hot coding to vectorize the labels\n",
    "model.fit(X_train, encoder(y_train), epochs=30, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f7c18",
   "metadata": {},
   "source": [
    "## Evaluate the vanilla RNN based on the testing set in the cell below (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f0b7d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# get predictions for test data and use argmax to convert output vector to labels\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c290f83d",
   "metadata": {},
   "source": [
    "## Present the classification accuracy and confusion matrix of the vanilla RNN in the cell below (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb933152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[451984  49225      0      0      0      0      0      0      0      0]\n",
      " [194735 227304      0    459      0      0      0      0      0      0]\n",
      " [  6947  39748      5    922      0      0      0      0      0      0]\n",
      " [  3567  15803      4   1747      0      0      0      0      0      0]\n",
      " [   566   3319      0      0      0      0      0      0      0      0]\n",
      " [  1817    179      0      0      0      0      0      0      0      0]\n",
      " [    14   1163      5    242      0      0      0      0      0      0]\n",
      " [     1    127      0    102      0      0      0      0      0      0]\n",
      " [     0     12      0      0      0      0      0      0      0      0]\n",
      " [     0      3      0      0      0      0      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3cb91b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7813/7813 [==============================] - 64s 8ms/step - loss: 0.0442 - accuracy: 0.6810\n"
     ]
    }
   ],
   "source": [
    "# get model accuracy\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, encoder(y_test), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "666f9625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the vanilla RNN model is: 0.6810399889945984\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of the vanilla RNN model is: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5468eca",
   "metadata": {},
   "source": [
    "## Implement the second RNN based on LSTM or GRU neurons in the cell below (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a564eae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 100)           40800     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 10, 150)           150600    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 50)                40200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 232,110\n",
      "Trainable params: 232,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "model_l = Sequential() # create a sequential model\n",
    "\n",
    "model_l.add(LSTM(units=100, input_shape=(10,1), activation='tanh', return_sequences=True))  # add LSTM neurons to the model\n",
    "model_l.add(LSTM(units=150, activation='tanh', return_sequences=True))  \n",
    "model_l.add(LSTM(units=50, activation='tanh'))  \n",
    "\n",
    "model_l.add(Dense(units=10, activation='tanh')) # add dense layer as the output layer of the model\n",
    "\n",
    "model_l.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model_l.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67424812",
   "metadata": {},
   "source": [
    "## Train the second RNN based on the training set in the cell below (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48addae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "196/196 - 12s - loss: 0.0575 - accuracy: 0.4934 - 12s/epoch - 62ms/step\n",
      "Epoch 2/30\n",
      "196/196 - 8s - loss: 0.0569 - accuracy: 0.5008 - 8s/epoch - 41ms/step\n",
      "Epoch 3/30\n",
      "196/196 - 8s - loss: 0.0565 - accuracy: 0.5138 - 8s/epoch - 43ms/step\n",
      "Epoch 4/30\n",
      "196/196 - 9s - loss: 0.0559 - accuracy: 0.5356 - 9s/epoch - 44ms/step\n",
      "Epoch 5/30\n",
      "196/196 - 9s - loss: 0.0555 - accuracy: 0.5413 - 9s/epoch - 43ms/step\n",
      "Epoch 6/30\n",
      "196/196 - 8s - loss: 0.0554 - accuracy: 0.5409 - 8s/epoch - 42ms/step\n",
      "Epoch 7/30\n",
      "196/196 - 9s - loss: 0.0554 - accuracy: 0.5413 - 9s/epoch - 45ms/step\n",
      "Epoch 8/30\n",
      "196/196 - 9s - loss: 0.0552 - accuracy: 0.5413 - 9s/epoch - 45ms/step\n",
      "Epoch 9/30\n",
      "196/196 - 9s - loss: 0.0551 - accuracy: 0.5474 - 9s/epoch - 43ms/step\n",
      "Epoch 10/30\n",
      "196/196 - 9s - loss: 0.0551 - accuracy: 0.5455 - 9s/epoch - 43ms/step\n",
      "Epoch 11/30\n",
      "196/196 - 9s - loss: 0.0550 - accuracy: 0.5477 - 9s/epoch - 45ms/step\n",
      "Epoch 12/30\n",
      "196/196 - 8s - loss: 0.0548 - accuracy: 0.5509 - 8s/epoch - 43ms/step\n",
      "Epoch 13/30\n",
      "196/196 - 8s - loss: 0.0545 - accuracy: 0.5584 - 8s/epoch - 42ms/step\n",
      "Epoch 14/30\n",
      "196/196 - 8s - loss: 0.0541 - accuracy: 0.5639 - 8s/epoch - 42ms/step\n",
      "Epoch 15/30\n",
      "196/196 - 8s - loss: 0.0537 - accuracy: 0.5678 - 8s/epoch - 43ms/step\n",
      "Epoch 16/30\n",
      "196/196 - 9s - loss: 0.0533 - accuracy: 0.5752 - 9s/epoch - 47ms/step\n",
      "Epoch 17/30\n",
      "196/196 - 9s - loss: 0.0532 - accuracy: 0.5764 - 9s/epoch - 47ms/step\n",
      "Epoch 18/30\n",
      "196/196 - 9s - loss: 0.0530 - accuracy: 0.5791 - 9s/epoch - 47ms/step\n",
      "Epoch 19/30\n",
      "196/196 - 9s - loss: 0.0527 - accuracy: 0.5827 - 9s/epoch - 48ms/step\n",
      "Epoch 20/30\n",
      "196/196 - 10s - loss: 0.0526 - accuracy: 0.5837 - 10s/epoch - 49ms/step\n",
      "Epoch 21/30\n",
      "196/196 - 9s - loss: 0.0522 - accuracy: 0.5885 - 9s/epoch - 46ms/step\n",
      "Epoch 22/30\n",
      "196/196 - 9s - loss: 0.0514 - accuracy: 0.5983 - 9s/epoch - 46ms/step\n",
      "Epoch 23/30\n",
      "196/196 - 9s - loss: 0.0499 - accuracy: 0.6176 - 9s/epoch - 48ms/step\n",
      "Epoch 24/30\n",
      "196/196 - 9s - loss: 0.0464 - accuracy: 0.6573 - 9s/epoch - 47ms/step\n",
      "Epoch 25/30\n",
      "196/196 - 9s - loss: 0.0430 - accuracy: 0.6904 - 9s/epoch - 45ms/step\n",
      "Epoch 26/30\n",
      "196/196 - 9s - loss: 0.0398 - accuracy: 0.7223 - 9s/epoch - 47ms/step\n",
      "Epoch 27/30\n",
      "196/196 - 10s - loss: 0.0354 - accuracy: 0.7634 - 10s/epoch - 51ms/step\n",
      "Epoch 28/30\n",
      "196/196 - 10s - loss: 0.0323 - accuracy: 0.7889 - 10s/epoch - 52ms/step\n",
      "Epoch 29/30\n",
      "196/196 - 10s - loss: 0.0301 - accuracy: 0.8017 - 10s/epoch - 49ms/step\n",
      "Epoch 30/30\n",
      "196/196 - 9s - loss: 0.0278 - accuracy: 0.8204 - 9s/epoch - 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f786c6b6eb0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "encoder=CategoryEncoding(num_tokens=10, output_mode=\"one_hot\") # one hot coding to vectorize the labels\n",
    "model_l.fit(X_train, encoder(y_train), epochs=30, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3522ea",
   "metadata": {},
   "source": [
    "## Evaluate the second RNN based on the testing set in the cell below (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7279608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# get predictions for test data and use argmax to convert output vector to labels\n",
    "\n",
    "y_pred_l = np.argmax(model_l.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a03ed1",
   "metadata": {},
   "source": [
    "## Present the classification accuracy and confusion matrix of the second RNN in the cell below (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4805e452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[478199  22971      4     35      0      0      0      0      0      0]\n",
      " [ 98376 322285   1155    682      0      0      0      0      0      0]\n",
      " [   137  34880  11168   1437      0      0      0      0      0      0]\n",
      " [   720   7141    254  13006      0      0      0      0      0      0]\n",
      " [  3042    815     14     13      1      0      0      0      0      0]\n",
      " [  1878    113      0      5      0      0      0      0      0      0]\n",
      " [     0    288    481    655      0      0      0      0      0      0]\n",
      " [     0     34      9    187      0      0      0      0      0      0]\n",
      " [    11      1      0      0      0      0      0      0      0      0]\n",
      " [     2      1      0      0      0      0      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f00b8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7813/7813 [==============================] - 128s 16ms/step - loss: 0.0268 - accuracy: 0.8247\n"
     ]
    }
   ],
   "source": [
    "# get model accuracy\n",
    "\n",
    "loss_l, accuracy_l = model_l.evaluate(X_test, encoder(y_test), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48c3e31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the LSTM based RNN model is: 0.824658989906311\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of the LSTM based RNN model is: {}\".format(accuracy_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b792b2df",
   "metadata": {},
   "source": [
    "## Answer the following question in the cell below  (10 marks).\n",
    "\n",
    "## Question:\n",
    "Compare the advantages and disadvantages of the two models you have implemented and give some ideas on how to improve these results/performance further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16b5401",
   "metadata": {},
   "source": [
    "Here is a comparison of the advantages and disadvantages of the two models:\n",
    "\n",
    "1. LSTM provides a much higher accuracy with smaller number of LSTM layers and units compared to simpleRNN.\n",
    "2. The number of trainable parameters for LSTMs is significantly higher than RNNs.\n",
    "\n",
    "To improve the models further a number of model hyperparameters can be tuned including activations, weights initialization, optimizers etc. For both LSTMs and RNNs, the number of units and layers can be increased until the loss continues to reduce on a validation split of the data and dropout can be used for LSTM since LSTMs usually overfit the data with a large number of layers. Additionally, the models can be trained for a higher number of epochs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e033b",
   "metadata": {},
   "source": [
    "## Additional remarks:\n",
    "\n",
    "Code outline appropriately commented. (10 marks)\n",
    "\n",
    "Code running without errors. (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825187c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
